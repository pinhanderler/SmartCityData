{"cells":[{"cell_type":"code","source":["%run \"./nb_logging\""],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":5,"statement_ids":[3,4,5],"state":"finished","livy_statement_state":"available","session_id":"e9e8d624-10e0-4f06-9fbd-8070c400c7e5","normalized_state":"finished","queued_time":"2025-12-24T21:04:10.778747Z","session_start_time":"2025-12-24T21:04:10.7790589Z","execution_start_time":"2025-12-24T21:04:24.1384324Z","execution_finish_time":"2025-12-24T21:04:24.7752761Z","parent_msg_id":"33322797-0092-46b2-a3ef-3edce88697d1"},"text/plain":"StatementMeta(, e9e8d624-10e0-4f06-9fbd-8070c400c7e5, 5, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Config Loaded\nLogging System Loaded\n"]}],"execution_count":1,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"b4c67d0c-506a-4431-a1ec-9f526d5ad1dd"},{"cell_type":"code","source":["from pyspark.sql import SparkSession, DataFrame\n","from pyspark.sql import DataFrame \n","from pyspark.sql.functions import *\n","from pyspark.sql.types import *\n","from delta.tables import *\n","import re\n","\n","spark = SparkSession.builder.getOrCreate()"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":6,"statement_ids":[6],"state":"finished","livy_statement_state":"available","session_id":"e9e8d624-10e0-4f06-9fbd-8070c400c7e5","normalized_state":"finished","queued_time":"2025-12-24T21:04:09.8458792Z","session_start_time":null,"execution_start_time":"2025-12-24T21:04:24.7772505Z","execution_finish_time":"2025-12-24T21:04:25.2193771Z","parent_msg_id":"55da602e-9a87-4049-ac77-3473546e97f4"},"text/plain":"StatementMeta(, e9e8d624-10e0-4f06-9fbd-8070c400c7e5, 6, Finished, Available, Finished)"},"metadata":{}}],"execution_count":2,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"fc221cfb-07d2-41b9-888b-425246908780"},{"cell_type":"code","source":["# ===============================\n","# COLUMN CLEANING\n","# ===============================\n","def clean_column_names(df: DataFrame) -> DataFrame:\n","    \"\"\"\n","    Converts DataFrame column names to snake_case\n","    \"\"\"\n","    def to_snake_case(name: str) -> str:\n","        name = re.sub(r\"[^\\w\\s]\", \"\", name)\n","        name = re.sub(r\"\\s+\", \"_\", name)\n","        return name.lower()\n","\n","    new_columns = [to_snake_case(c) for c in df.columns]\n","    return df.toDF(*new_columns)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":7,"statement_ids":[7],"state":"finished","livy_statement_state":"available","session_id":"e9e8d624-10e0-4f06-9fbd-8070c400c7e5","normalized_state":"finished","queued_time":"2025-12-24T21:04:09.9012911Z","session_start_time":null,"execution_start_time":"2025-12-24T21:04:25.2214829Z","execution_finish_time":"2025-12-24T21:04:25.6699272Z","parent_msg_id":"6e7b6e63-5886-4e76-8447-baf8d2465ffe"},"text/plain":"StatementMeta(, e9e8d624-10e0-4f06-9fbd-8070c400c7e5, 7, Finished, Available, Finished)"},"metadata":{}}],"execution_count":3,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"543028ef-2bb0-44e1-ab99-82053eb01993"},{"cell_type":"code","source":["# ===============================\n","# EXPLODE & FLATTEN\n","# ===============================\n","\n","def explode_and_flatten(df):\n","    for field in df.schema.fields:\n","        if isinstance(field.dataType, ArrayType) and isinstance(field.dataType.elementType, StructType):\n","            struct_name = field.name\n","            df = df.withColumn(struct_name, explode(col(struct_name)))\n","            for f in field.dataType.elementType.fields:\n","                df = df.withColumn(f\"{struct_name}_{f.name}\", col(f\"{struct_name}.{f.name}\"))\n","            df = df.drop(struct_name)\n","        elif isinstance(field.dataType, StructType):\n","            struct_name = field.name\n","            array_fields = [\n","                f\"{struct_name}.{f.name}\"\n","                for f in field.dataType.fields\n","                if isinstance(f.dataType, ArrayType)\n","            ]\n","            if not array_fields:\n","                continue\n","            df = df.withColumn(\n","                f\"{struct_name}_zip\",\n","                arrays_zip(*[col(c) for c in array_fields])\n","            ).withColumn(\n","                f\"{struct_name}_zip\",\n","                explode(col(f\"{struct_name}_zip\"))\n","            )\n","            for f in field.dataType.fields:\n","                if isinstance(f.dataType, ArrayType):\n","                    df = df.withColumn(\n","                        f\"{struct_name}_{f.name}\",\n","                        col(f\"{struct_name}_zip.{f.name}\")\n","                    )\n","            df = df.drop(f\"{struct_name}_zip\")\n","    return df"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":8,"statement_ids":[8],"state":"finished","livy_statement_state":"available","session_id":"e9e8d624-10e0-4f06-9fbd-8070c400c7e5","normalized_state":"finished","queued_time":"2025-12-24T21:04:09.963562Z","session_start_time":null,"execution_start_time":"2025-12-24T21:04:25.6721465Z","execution_finish_time":"2025-12-24T21:04:26.2120502Z","parent_msg_id":"4df3e7d1-3b2f-4184-98e5-a52c64137e61"},"text/plain":"StatementMeta(, e9e8d624-10e0-4f06-9fbd-8070c400c7e5, 8, Finished, Available, Finished)"},"metadata":{}}],"execution_count":4,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"7cb4edf2-1554-427f-a398-afa2d762afdd"},{"cell_type":"code","source":["# ===============================\n","# SAVE TO LAKEHOUSE\n","# ===============================\n","def save_to_lakehouse(\n","    df: DataFrame,\n","    path: str,\n","    source: str,\n","    mode: str = \"overwrite\"\n","):\n","    \"\"\"\n","    Saves DataFrame to Lakehouse with logging\n","    \"\"\"\n","    try:\n","        log_process_start(source, \"save_to_lakehouse\")\n","        df.write.mode(mode).parquet(path)\n","        log_process_end(source, \"save_to_lakehouse\")\n","    except Exception as e:\n","        log_error(source, \"save_to_lakehouse\", f\"Error saving to {path}\", str(e))\n","        raise"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":9,"statement_ids":[9],"state":"finished","livy_statement_state":"available","session_id":"e9e8d624-10e0-4f06-9fbd-8070c400c7e5","normalized_state":"finished","queued_time":"2025-12-24T21:04:10.0079855Z","session_start_time":null,"execution_start_time":"2025-12-24T21:04:26.2138841Z","execution_finish_time":"2025-12-24T21:04:26.7401332Z","parent_msg_id":"cc437199-1306-4225-baba-af46398df1fb"},"text/plain":"StatementMeta(, e9e8d624-10e0-4f06-9fbd-8070c400c7e5, 9, Finished, Available, Finished)"},"metadata":{}}],"execution_count":5,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"e465c864-58ef-4568-b014-5b70d4101825"},{"cell_type":"code","source":["# ===============================\n","# SURROGATE KEY\n","# ===============================\n","def generate_surrogate_key(\n","    df: DataFrame,\n","    columns: list,\n","    key_name: str = \"surrogate_key\"\n",") -> DataFrame:\n","    \"\"\"\n","    Generates MD5 hash surrogate key\n","    \"\"\"\n","    return df.withColumn(key_name, md5(concat_ws(\"||\", *columns)))"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":10,"statement_ids":[10],"state":"finished","livy_statement_state":"available","session_id":"e9e8d624-10e0-4f06-9fbd-8070c400c7e5","normalized_state":"finished","queued_time":"2025-12-24T21:04:10.0667698Z","session_start_time":null,"execution_start_time":"2025-12-24T21:04:26.7421632Z","execution_finish_time":"2025-12-24T21:04:27.1991992Z","parent_msg_id":"e0838b74-ee41-448f-9be8-5d1031d791a1"},"text/plain":"StatementMeta(, e9e8d624-10e0-4f06-9fbd-8070c400c7e5, 10, Finished, Available, Finished)"},"metadata":{}}],"execution_count":6,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"0edb554f-342d-4b8b-8291-ee89709433d0"},{"cell_type":"code","source":["# ===============================\n","# TIME SERIES FRAME\n","# ===============================\n","def create_time_series_frame(\n","    df: DataFrame,\n","    time_column: str = \"timestamp\"\n",") -> DataFrame:\n","    \"\"\"\n","    Adds date column from timestamp\n","    \"\"\"\n","    return df.withColumn(\"date\", to_date(col(time_column)))"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":11,"statement_ids":[11],"state":"finished","livy_statement_state":"available","session_id":"e9e8d624-10e0-4f06-9fbd-8070c400c7e5","normalized_state":"finished","queued_time":"2025-12-24T21:04:10.1180205Z","session_start_time":null,"execution_start_time":"2025-12-24T21:04:27.2010547Z","execution_finish_time":"2025-12-24T21:04:27.699178Z","parent_msg_id":"edf46da0-a47d-4530-b718-956c94acc195"},"text/plain":"StatementMeta(, e9e8d624-10e0-4f06-9fbd-8070c400c7e5, 11, Finished, Available, Finished)"},"metadata":{}}],"execution_count":7,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"a9f9f7e8-dc3f-4f27-bbc7-14956acaa9a7"},{"cell_type":"code","source":["# ===============================\n","# JOIN HELPER\n","# ===============================\n","def join_dataframes(\n","    df1: DataFrame,\n","    df2: DataFrame,\n","    join_cols: list,\n","    how: str = \"inner\"\n",") -> DataFrame:\n","    \"\"\"\n","    Joins two DataFrames\n","    \"\"\"\n","    return df1.join(df2, on=join_cols, how=how)\n","\n","print(\"Functions Loaded\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":12,"statement_ids":[12],"state":"finished","livy_statement_state":"available","session_id":"e9e8d624-10e0-4f06-9fbd-8070c400c7e5","normalized_state":"finished","queued_time":"2025-12-24T21:04:10.157853Z","session_start_time":null,"execution_start_time":"2025-12-24T21:04:27.7012588Z","execution_finish_time":"2025-12-24T21:04:28.2033546Z","parent_msg_id":"53ebabdb-4425-4dca-8e78-4838077fda16"},"text/plain":"StatementMeta(, e9e8d624-10e0-4f06-9fbd-8070c400c7e5, 12, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Functions Loaded\n"]}],"execution_count":8,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"e4ecc86c-c3a8-449a-a24a-191900717ae1"},{"cell_type":"code","source":["def set_columns_safe(df: DataFrame, cols: list) -> DataFrame:\n","    \"\"\"\n","    Select only existing columns (safe select)\n","    \"\"\"\n","    existing_cols = [c for c in cols if c in df.columns]\n","    return df.select(*existing_cols)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":13,"statement_ids":[13],"state":"finished","livy_statement_state":"available","session_id":"e9e8d624-10e0-4f06-9fbd-8070c400c7e5","normalized_state":"finished","queued_time":"2025-12-24T21:04:10.2065667Z","session_start_time":null,"execution_start_time":"2025-12-24T21:04:28.2052759Z","execution_finish_time":"2025-12-24T21:04:28.7004442Z","parent_msg_id":"9947d119-b7cf-49b1-bbec-cb509c285f02"},"text/plain":"StatementMeta(, e9e8d624-10e0-4f06-9fbd-8070c400c7e5, 13, Finished, Available, Finished)"},"metadata":{}}],"execution_count":9,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"9b94e0fa-0499-4d75-aa7d-c769c3e279a8"},{"cell_type":"code","source":["def filter_last_7_days(df: DataFrame, timestamp_col: str) -> DataFrame:\n","    \"\"\"\n","    DataFrame'i timestamp_col üzerinden son 7 günle sınırlı tutar.\n","    \"\"\"\n","    return df.filter(col(timestamp_col) >= date_sub(current_date(), 7))"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":14,"statement_ids":[14],"state":"finished","livy_statement_state":"available","session_id":"e9e8d624-10e0-4f06-9fbd-8070c400c7e5","normalized_state":"finished","queued_time":"2025-12-24T21:04:10.243969Z","session_start_time":null,"execution_start_time":"2025-12-24T21:04:28.7025089Z","execution_finish_time":"2025-12-24T21:04:29.1652367Z","parent_msg_id":"ae2720c9-3a84-4cde-b7e9-0deff50ec358"},"text/plain":"StatementMeta(, e9e8d624-10e0-4f06-9fbd-8070c400c7e5, 14, Finished, Available, Finished)"},"metadata":{}}],"execution_count":10,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"deb9cd2a-d1ba-4b2b-bd9c-0bcaf84b2335"},{"cell_type":"markdown","source":["# -------------------------------\n","# Functions(DataFrame)\n","# -------------------------------\n","def clean_column_names(df: DataFrame) -> DataFrame:\n","    def to_snake_case(name):\n","        name = re.sub(r'[^0-9a-zA-Z_]', '', name)\n","        name = re.sub(r'\\s+', '_', name)\n","        return name.lower()\n","    new_columns = [to_snake_case(c) for c in df.columns]\n","    return df.toDF(*new_columns)\n","\n","def explode_and_flatten(df: DataFrame) -> DataFrame:\n","    while True:\n","        flatten_cols = [f.name for f in df.schema.fields if isinstance(f.dataType, StructType)]\n","        explode_cols  = [f.name for f in df.schema.fields if isinstance(f.dataType, ArrayType)]\n","        if not flatten_cols and not explode_cols:\n","            break\n","        for c in flatten_cols:\n","            struct_fields = [f.name for f in df.schema[c].dataType.fields]\n","            flatten_expr = [col(f\"{c}.{f}\").alias(f\"{c}_{f}\") for f in struct_fields]\n","            df = df.select([col(c) for c in df.columns if c != c] + flatten_expr)\n","        for c in explode_cols:\n","            df = df.withColumn(c, explode(col(c)))\n","    return df\n","\n","def create_time_series_frame(df: DataFrame, time_column: str) -> DataFrame:\n","    return df.withColumn(\"date\", to_date(col(time_column)))\n","\n","def generate_surrogate_key(df: DataFrame, columns: list, key_name=\"surrogate_key\") -> DataFrame:\n","    return df.withColumn(key_name, md5(concat_ws(\"||\", *columns)))\n","\n","def save_to_lakehouse(df: DataFrame, path: str, source: str, mode=\"overwrite\"):\n","    try:\n","        df.write.mode(mode).parquet(path)\n","        log_process_end(source, \"save_to_lakehouse\")\n","    except Exception as e:\n","        log_error(source, \"save_to_lakehouse\", f\"Error saving {path}\", e)\n","        \n"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"adf94c4d-5d77-4ed5-a631-e9642845c3d4"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","display_name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{"known_lakehouses":[{"id":"4ed0e237-04d9-4f52-be5a-2fa5b9fb7c8a"}],"default_lakehouse":"4ed0e237-04d9-4f52-be5a-2fa5b9fb7c8a","default_lakehouse_name":"Project_Lakehouse","default_lakehouse_workspace_id":"e5c59b1a-f845-4467-b859-d65a059702db"}}},"nbformat":4,"nbformat_minor":5}